title: 读《OpenCL异构计算（第二版）》
date: 2014-12-07 09:02:56
categories: 读书
tags: [OpenCL,GPU]

---

读这本书最主要原因是为了毕业设计---**《图像处理算法的高效GPU实现》**。这次的选题算是一个挑战，大家都想着毕设拿出自己最拿手的作品，我却在摸索一个不甚了解的领域。但是“**挑战**”这种东西似乎从来都不是个问题，反之正因为陌生反而激发了我的兴趣，就是这么任性！

读书，我喜欢看书开头的**序**，它能很直观的体现出作者的态度。“**我希望您能帮我一个忙，我希望您能阅读这本书**”，这样的开头无疑已经让我钦佩于作者的诚恳与谦和，不认真拜读似乎都成了一件十分残忍的事情。

所以我该做些什么呢？认真的拜读和学习这本书。
<!--more-->
> <center>2014-12-07 10:41:19 随笔至此，待续</center>

---
## 第一章：并行编程入门

### OpenCL
开放计算语言（Open Computing Language, OpenCL）是非盈利性技术联盟 Khronos Group 管理的异构变成框架。

OpenCL 提供了系统内各个设备的设备端语言和主机端控制层两方面的定义。

OpenCL 提供了基于任务和基于数据的两种并行计算方式。

OpenCL 支持的体系架构众多，包括多核 CPU，GPU 之类的的吐吞量和向量处理器以及 FPGA 之类的细粒度并行设备。

OpenCL 是跨平台的。

### 并行思维

概念解释:
- 并行是指在同一时刻，有多条指令在处理器上同时执行。
- 并发是指在同一时刻只能有一条指令执行，但多个进程指令快速轮换执行，使得宏观上具有多个进程同时执行的效果。

1. 数据并行:

2. 任务并行:

### 并发编程模型和并行编程模型

#### 线程和共享内存

线程之间的通信通过读写同一个地址空间的内存来完成。每个线程拥有自己的局部内存池---即变量---但所有线程可以看到同样的全局变量集。

**内存一致性模型**被用来管理内存读取和写入的顺序。所有进程看到的是同样的地址空间，并在其他进程的帮助下直接访问这些地址。lock/semaphore 这样的机制常用来控制多个任务对同一段共享内存的访问。共享内存的模型的一个**主要特征**是程序员不需要考虑数据移动。

#### 消息传递通信

有了消息传递通信模型，我们能详细指定计算时可能会使用内存的一系列任务之间如何进行通信。若干个任务可以位于同一个物理设备或跨多个设备（数量不限）。任务通过通信发送和接收具体的消息来实现数据交换。数据传输通常需要各个进程执行协同操作。例如，一个是发送程序必须有一个匹配的接收操作。

#### 不同粒度的并行

在并行计算中，粒度定义为**计算与通信之比**。通信和计算交错出现，并通过同步事件明确区分开。并行粒度受限于应用程序算法的内在特性。

选择正确的并行粒度有助于程序暴露更多的可并行性，从而充分发挥基础平台的性能。

选择多大的并行粒度更多取决于算法本身和其运行的硬件环境。在大多数情况下，如果额外的通信和同步开销和当前计算时间之比越高，那么采用粗粒度并行对工作越有利。细粒度并行有助于减少由于负载不均衡和访存延迟所带来的开销。

#### 数据共享和同步

## 第二章：OpenCL简介

OpenCL 规范由四个模型组成：
- 平台模型：描述了协同执行的单个处理器（宿主机）及一个或多个能执行OpenCL代码的处理器（设备）。它定义了一个抽象的硬件模型，供编程人员用于编写能够在这些设备上执行的OpenCL C函数（称作 kernel）。
- 执行模型：定义了在主机上配置OpenCL环境以及如何在设备上执行kernel。这包括在主机端建立OpenCL上下文，提供主机-设备之间的交互机制，定义一个并发模型供在设备上执行kernel所用。
- 内存模型：定义被kernel所用的抽象内存层次，无需考虑实际的底层内存架构。尽管内存模型十分接近当前的GPU内存层次，但同样也适用于其他硬件加速器。
- 编程模型：定义了如何将并发模型映射到物理硬件上。

kernel和OpenCL执行模型：
kernel是OpenCL程序在设备实际运行的那部分代码。
NDRange、work-item、workgroup等的概念解析参照[OpenCL:一种异构计算架构](http://www.cnblogs.com/wangshide/archive/2012/01/07/2315830.html#sec-3.3.1)